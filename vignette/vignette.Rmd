---
title: 'A quick guide to "spatialGLM_stacking"'
subtitle: 'Bayesian inference for geostatistical count data using predictive stacking'
author: "Soumyakanti Pan, e-mail: span18@ucla.edu"
date: \today
output: 
  bookdown::html_document2:
    mathjax: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    # self_contained: true
    theme: spacelab
    highlight: pygments
    toc: true
    number_sections: true
    df_print: kable
    citation_package: natbib
    code_folding: show
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage{amsmath, amssymb, amsfonts, bm}
  - \def\T{{ \top }}
  - \newcommand{\iid}{\stackrel{\mathclap{\normalfont\tiny\mbox{iid}}}{\sim}}
  - \newcommand{\given}{\mid}
  - \newcommand{\biggiven}{\,\middle|\,}
  - \newcommand{\E}{\mathbb{E}}
  - \newcommand{\V}{\mathbb{V}}
  - \newcommand{\defeq}{\vcentcolon=}
  - \newcommand{\GP}{\mathrm{GP}}
  - \newcommand{\EF}{\mathrm{EF}}
  - \newcommand{\DY}{\mathrm{DY}}
  - \newcommand{\CM}{\mathrm{CM}}
  - \newcommand{\CMP}{\mathrm{CMP}}
  - \newcommand{\GCM}{\mathrm{GCM}}
  - \newcommand{\CMc}{\mathrm{CM_c}}
  - \newcommand{\GCMc}{\mathrm{GCM_c}}
  - \newcommand{\thetasp}{{\theta_{\text{sp}}}}
  - \newcommand{\calD}{\mathcal{D}}
  - \newcommand{\calL}{\mathcal{L}}
  - \newcommand{\calS}{\mathcal{S}}
  - \newcommand{\calT}{\mathcal{T}}
bibliography: refs.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA,
                      opts.label="kill_prefix", messages = FALSE,
                      fig.align = 'center', fig.height = 3)
```

# Introduction
This document is a guide to the code as it appears on the GitHub repository [spatialGLM_stacking](https://github.com/SPan-18/spatialGLM_stacking) that we have developed in order to implement Bayesian predictive stacking for analyzing outcomes that arrive as counts over spatial-temporal coordinates.

## A brief summary 
Analyzing non-Gaussian spatial-temporal data typically requires introducing spatial dependence in generalized linear models through the link function of an exponential family distribution. However, unlike in Gaussian likelihoods, inference is considerably encumbered by the inability to analytically integrate out the random effects and reduce the dimension of the parameter space. We propose exploiting generalized conjugate multivariate distribution theory [@bradley2023lgp] for exponential families, which enables exact sampling from analytically available posterior distributions conditional upon some fixed process parameters. Subsequently, we combine inference from these individual posterior distributions over a range of values of these parameters using Bayesian predictive stacking. The subsequent sections provide a brief summary on usage of the functions we developed to fit various spatial as well as spatial-temporal regressions on count data with fixed regression coefficients as well spatially-temporally varying regression coefficients.

## Package requirements
Successful run of the functions depends on installation of the following packages - `MASS`, `parallel`, `progress`, `dplyr`, `knitr`, `spBayes`, `CVXR` and `Rcpp`. Installation of `ggplot2`, `MBA`, `latex2exp` are required for reproducing graphical outputs. Installation of `Rfast`, `loo`, `Rmosek` and `geoR` are optional. The package `Rmosek` is an R interface for using the solver [MOSEK](https://docs.mosek.com/9.3/rmosek/index.html) which requires a license. One may obtain the license using academic email for free. Otherwise, one may use other solvers provided by `CVXR`, details of which will be provided in the respective sections.

```{r packages, eval=FALSE}
# Required package names
packages <- c("MASS", "parallel", "progress", "dplyr", "knitr", "CVXR", "Rcpp",
              "ggplot2", "ggpubr", "MBA", "latex2exp", "scales",
              "loo", "Rmosek", "geoR", "spBayes")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
```

## Load functions
First, we include the required packages and loads all functions in the directory \texttt{./src}.
```{r runsrc}
# clear environment
rm(list = ls())

# load all functions
source("../src/runsrc.R")
```

# Spatial regressions
Let $y(s)$ be the outcome of interest at location $s \in \calD$ that is endowed with a probability law from the natural exponential family, which we denote by 
\begin{equation}
    y(s) \sim \EF(x(s)^\T \beta  + z(s); b, \psi_y)
    (\#eq:NEF)
\end{equation}
for some real parameter $b > 0$ and unit log partition function $\psi_y$. We consider the cases where response $y(s)$ follows a Poisson distribution or a binomial distribution. We generate synthetic data based on the model above where $z(s) \sim \GP(0, \sigma^2_z R(\cdot, \cdot; \phi, \nu))$ is a Gaussian process with Matern covariogram specified by spatial decay parameter $\phi$ and smoothness parameter $\nu$. 
\begin{equation}
R(s, s'; \thetasp) = \frac{(\phi \lvert s - s' \rvert)^\nu}{2^{\nu - 1} \Gamma(\nu)} K_\nu (\phi \lvert s - s' \rvert))
(\#eq:matern)
\end{equation}
For generating synthetic data, we consider $x(s)$ to be $p$-dimensional containing an intercept and other variables sampled independently from a standard normal distribution.

## Spatial Poisson regression
### Simulation of synthetic data
We generate the synthetic spatial Poisson count data following model \@ref(eq:NEF) with sample size $n = 100$ and locations sampled uniformly from $[0, 1]^2$, the unit square and, $\sigma^2_z = 0.4$, $\beta = (5, -0.5)$ and, latent Gaussian process with correlation function \@ref(eq:matern) with $\phi = 3.5$ and $\nu = 0.5$ (exponential covariogram)
\begin{equation}
\begin{split}
y(s_i) &\sim \mathrm{Poisson}(\lambda(s_i)), \quad i = 1, \dots, 100.\\
\lambda(s_i) & = \exp(x(s_i)^\T \beta + z(s_i))
\end{split}
(\#eq:sim1)
\end{equation}
We use the function `sim_count` for generate the above specified synthetic Poisson count data.

```{r sim1, cache=TRUE, cache.path="cache/"}
set.seed(1729)
beta0 <- c(5, -0.5)
simdat <- sim_count(n = 100, beta = beta0, phi = 3.5)

print(head(simdat))
```
```{r, fig.cap="Simulated point-referenced Poisson count data."}
# Plot point-referenced counts
ggplot(simdat, aes(x = s1, y = s2)) +
  geom_point(aes(color = y, size = y), alpha = 0.75) +
  scale_color_distiller(palette = "RdYlGn", direction = -1,
                        label = function(x) sprintf("%.0f", x)) +
  guides(alpha = 'none', size = 'none') + 
  xlab("Easting") + ylab("Northing") +
  labs(color = TeX('$y(s)$')) + theme_bw() +
  theme(axis.ticks = element_line(linewidth = 0.25),
        panel.background = element_blank(),
        panel.grid = element_blank(), 
        legend.title = element_text(size = 10, hjust = 0.25), 
        legend.box.just = "center", aspect.ratio = 1)
```

### Fitting Poisson regression using stacking
We first store our data into the variables `y`, `X` and `S` which corresponds to the $n \times 1$ response vector $y$, the $n \times p$ design matrix $X$ and the $n \times 2$ matrix storing the locations of each response.
```{r}
y <- as.numeric(simdat$y)
X <- as.matrix(simdat[, grep("x", names(simdat))])
S <- as.matrix(simdat[, c("s1", "s2")])
```

Next, we build the collection of candidate models using the function `create_model_list()` based on the spatial decay and smoothness parameters and some auxiliary model parameters that includes a boundary adjustment parameter, candidate values of which are given in the argument `G_epsilon` and the variance parameter of the fine-scale variation, candidate values of which are given by `G_nuxi`. The inputs `G_nubeta` and `G_nuz` corresponds to fixed hyperparameters of the scale parameters of the regression coefficient and the spatial process respectively. The candidate values of the decay parameter $\phi$ are chosen in a way that it covers 20\%, 50\% and 70\% of the maximum inter-site distance. The candidate values the spatial smoothness parameter are chosen to be customary values common in spatial analysis. User may attempt to minimize the total number of models (say, $L$) by choosing less number of informative candidate values of the parameters and hence drastically lowering the number of candidate models $\{M_1, \dots, M_L\}$ being fit, thus improving runtime.
```{r}
mod_list <- create_model_list(G_decay = c(3, 4, 10), 
                              G_smoothness = c(0.5, 1, 1.5),
                              G_epsilon = c(0.5, 0.75),
                              G_nuxi = c(1),
                              G_nubeta = 3, G_nuz = 3)
```

Now, we choose how many posterior samples we want to obtain and implement our proposed stacking algorithm using the function `spGLM_stack()`. The option `MC.samp` controls how many Monte Carlo samples we consider to find the leave-one-out predictive densities (LOO-PD), whereas the option `CV_fold` controls the value of $K$ in order to carry out a $K$-fold cross-validation approach for fast evaluation of LOO-PD. If we set `mc.cores = NULL`, then the algorithm is not parallelised over multiple cores, whereas the user may choose this value based on the computational resource of their machine. If the user does not have a MOSEK license, then `solver = "ECOS"` may be used.
```{r stack1, cache=TRUE, cache.path="cache/"}
n_postsamp <- 500
m_out <- spGLM_stack(y = y, X = X, S = S, 
                     N.samp = n_postsamp, MC.samp = 200,
                     family = "poisson", spCov = "matern",
                     CV_fold = 10, mc.cores = 6, 
                     solver = "MOSEK",
                     mod_params_list = mod_list)
```

Now, we look closely at the output `m_out` to understand how to use the stacking weights and posterior samples corresponding to each model. The output `m_out` is a 2-dimensional list with the first list named \texttt{models} and the second \texttt{weights}.
```{r}
str(m_out, max.level = 1)
```

The second list \texttt{weights} stores a $L$-dimensional vector of the stacking weights corresponding to each of the $L$ models. The first list \texttt{models} is itself a $L$-dimensional list with each list storing a $4$-dimensional list containing posterior samples of relevant model parameters and LOO-PD.
```{r}
str(m_out$models[[1]])
```

Given the stacking weights, one can sample from the $L$ models accordingly and obtain Bayesian inference on the regression coefficients, $\beta$ and the spatial random effect, $z$ by using the function `postrunsampler()`.
```{r}
postrun_samps <- postrunsampler(m_out, N.samp = n_postsamp)
post_z <- postrun_samps$z
post_beta <- postrun_samps$beta
```

We can now obtain inference on the regression coefficients from the following summary.
```{r}
print(ci_beta(t(post_beta)))
```

### Fitting Poisson regression using MCMC

We devise an adaptive Metropolis-within-Gibbs algorithm [@adaMetropGibbs_2009] to sample from the joint posterior distribution of the model parameters and the spatial process parameters $\phi$ and $\nu$ by using the function `spGCM_adaMetropGibbs()`.
```{r mcmc1, cache=TRUE, cache.path="cache/"}
n_postsamp <- 5000

mod_out <- spGCM_adaMetropGibbs(y = y, X = X, S = S, family = "poisson",
                                N.samp = n_postsamp, spCov = "matern",
                                starting = list(phi = 3, nu = 1,
                                                beta = c(0, 0)),
                                prior = list(phi = c(0.5, 10),
                                             nu = c(0.1, 2),
                                             nu_xi = 1,
                                             nu_beta = 2.1,
                                             nu_z = 2.1,
                                             alpha_epsilon = 0.5))
```

Next, we collect the posterior samples after removing burn-in samples and thinning to reduce autocorrelation in the chain.
```{r}
burnin_pc <- 0.5          # percentage burn-in
n_thin <- 5               # consider every *-th sample

ids <- 1:n_postsamp
ids <- ids[-(1:(floor(burnin_pc * n_postsamp))+1)]
ids <- ids[c(rep(FALSE, n_thin - 1), TRUE)]

post_beta_mcmc <- mod_out$beta[, ids]
post_z_mcmc <- mod_out$z[, ids]
post_phi_mcmc <- mod_out$phi[ids]
post_nu_mcmc <- mod_out$nu[ids]
```

Posterior distributions of the spatial process parameters can be analysed by histograms.
```{r, fig.cap = "Posterior distributions of spatial process parameters."}
post_spParams <- data.frame(vals = c(post_phi_mcmc, post_nu_mcmc), 
                            params = rep(c("phi", "nu"), each = length(post_phi_mcmc)))
spParams_names <- c('phi' = TeX('$\\phi$'), 'nu' = TeX('$\\nu$'))
spParams_labeller <- as_labeller(spParams_names, default = label_parsed)
ggplot(post_spParams, aes(x = vals)) + 
  geom_histogram(aes(y = after_stat(density)), bins = 50,
                 color = "black", fill = "royalblue4", alpha = 0.5) + 
  geom_density(fill = "skyblue", alpha = 0.25) +
  xlab("") + ylab("Posterior density") +
  facet_wrap(~ params, labeller = spParams_labeller, scales = "free") +
  theme_bw() + theme(panel.grid = element_blank())
```

### Comparison between stacking and MCMC

We compare the interpolated surfaces of the posterior median of the spatial random effects obtained by both our proposed method and MCMC in Figure \@ref(fig:surfaceplots) with that of the true spatial effect that was used to generate the synthetic data.

```{r surfaceplots, fig.cap="Interpolated surfaces of (a) true spatial effects, posterior median of spatial effects obtained by (b) MCMC, and (c) stacking."}
simdat$postmedian_z_mcmc <- apply(post_z_mcmc, 1, median)
simdat$postmedian_z_stack <- apply(post_z, 1, median)

p1 <- pointref_plot(simdat, "z", legend_title = NULL, mark_points = TRUE)
p2 <- pointref_plot(simdat, "postmedian_z_mcmc", legend_title = NULL)
p3 <- pointref_plot(simdat, "postmedian_z_stack", legend_title = NULL)

library(ggpubr)
ggarrange(p1, p2, p3, nrow = 1, labels = 'auto',
          common.legend = TRUE, legend="right")
```

Next, we compare the posterior distributions of the regression coefficients obtained by our stacking algorithm and MCMC by looking at density plots in Figure \@ref(fig:betaplots).
```{r class.source='fold-hide'}
post_beta_combined1 <- as.data.frame(t(as.matrix(post_beta_mcmc)))
post_beta_combined2 <- as.data.frame(t(as.matrix(post_beta)))
names(post_beta_combined1) <- c("beta0", "beta1")
names(post_beta_combined2) <- c("beta0", "beta1")
post_beta_combined1$Method <- "MCMC"
post_beta_combined2$Method <- "Stacking"
post_beta_combined <- rbind.data.frame(post_beta_combined1,
                                       post_beta_combined2,
                                       stringsAsFactors = TRUE)
row.names(post_beta_combined) <- NULL
post_beta_combined$Method <- factor(post_beta_combined$Method)

plot_beta0 <- ggplot(data = post_beta_combined, aes(x = beta0)) +
  geom_density(aes(fill = Method, color = Method), alpha = 0.3) +
  xlim(0, 10) + xlab(latex2exp::TeX('$\\beta_0$')) + theme_bw() +
  annotate("point", x = beta0[1], y = 0, pch = 24, fill = "#B4464B", size = 2) +
  theme(panel.grid = element_blank(), legend.background = element_blank(),
        legend.title = element_text(face = "italic", hjust = 0.5),
        axis.title.y=element_blank(), aspect.ratio = 1)

plot_beta1 <- ggplot(data = post_beta_combined, aes(x = beta1)) +
  geom_density(aes(fill = Method, color = Method), alpha = 0.3) +
  xlim(-1.5, 0.5) + xlab(latex2exp::TeX('$\\beta_1$')) + theme_bw() +
  annotate("point", x = beta0[2], y = 0, pch = 24, fill = "#B4464B", size = 2) + 
  theme(panel.grid = element_blank(), legend.background = element_blank(),
        legend.title = element_text(face = "italic", hjust = 0.5),
        axis.title.y=element_blank(), aspect.ratio = 1)
```

```{r betaplots, warning=FALSE, fig.cap='Comparison of posterior densities of regression coefficients.'}
ggarrange(plot_beta0, plot_beta1, nrow = 1,
          common.legend = TRUE, legend="right")
```

Next, we look at Q-Q plots to compare the posterior distributions of the regression coefficients in Figure \@ref(fig:qqbeta).
```{r class.source='fold-hide'}
qseq <- seq(0, 1, length.out = 100)
beta0_MCMC_q <- quantile(post_beta_combined1$beta0, qseq)
beta0_stack_q <- quantile(post_beta_combined2$beta0, qseq)
beta1_MCMC_q <- quantile(post_beta_combined1$beta1, qseq)
beta1_stack_q <- quantile(post_beta_combined2$beta1, qseq)

MCMCvsStack <- data.frame(beta0_MCMC_q = beta0_MCMC_q,
                          beta0_stack_q = beta0_stack_q,
                          beta1_MCMC_q = beta1_MCMC_q,
                          beta1_stack_q = beta1_stack_q)

p_qqbeta0 <- ggplot(MCMCvsStack, aes(x = beta0_MCMC_q, y = beta0_stack_q)) +
  geom_abline(slope = 1, intercept = 0, lty = 3, col = "red") +
  geom_point(col = "grey20", size = 2, alpha = 0.3) +
  labs(title = latex2exp::TeX('$\\beta_0$'), x ="MCMC", y = "Stacking") +
  xlim(0, 10) + ylim(0, 10) + theme_bw() +
  theme(panel.grid = element_blank(), aspect.ratio = 1,
        plot.title = element_text(hjust = 0.5))

p_qqbeta1 <- ggplot(MCMCvsStack, aes(x = beta1_MCMC_q, y = beta1_stack_q)) +
  geom_abline(slope = 1, intercept = 0, lty = 3, col = "red") +
  geom_point(col = "grey20", size = 2, alpha = 0.3) +
  labs(title = latex2exp::TeX('$\\beta_1$'), x ="MCMC", y = "Stacking") +
  xlim(-1.0, 0) + ylim(-1.0, 0) + theme_bw() +
  theme(panel.grid = element_blank(), aspect.ratio = 1,
        plot.title = element_text(hjust = 0.5))
```

```{r qqbeta, warning = FALSE, fig.cap='Comparison of posterior quantiles of regression coefficients.'}
ggarrange(p_qqbeta0, p_qqbeta1, nrow = 1)
```

## Spatial binomial regression
### Simulation of synthetic data
We generate the synthetic spatial binomial count data from model \@ref(eq:NEF) with sample size $n = 100$ and locations sampled uniformly from $[0, 1]^2$, the unit square and, $\sigma^2_z = 0.4$, $\beta = (1, -0.5)$ and, latent Gaussian process with correlation function \@ref(eq:matern) with spatial process parameters $\phi = 3.5$ and $\nu = 0.5$ (exponential covariogram)
\begin{equation}
\begin{split}
m(s_i) & \sim \mathrm{Poisson}(20), \quad i = 1, \dots, 100.\\
y(s_i) &\sim \mathrm{Binomial}(m(s_i), \pi(s_i)), \quad i = 1, \dots, 100. \\
\text{where, } \pi(s_i) &= \mathrm{ilogit}(x(s_i)^\T \beta + z(s_i)) = \frac{\exp(x(s_i)^\T \beta + z(s_i))}{1 + \exp(x(s_i)^\T \beta + z(s_i))}
\end{split}
(\#eq:sim2)
\end{equation}
We use the function `sim_binom` for generate the above specified synthetic Poisson count data.

```{r sim2, cache=TRUE, cache.path="cache/"}
set.seed(1729)
simdat2 = sim_binom(n = 100, n_binom = 20, beta = c(2, -0.5), phi = 3.5)
```
```{r class.source='fold-hide'}
pbinom1 <- ggplot(simdat2, aes(x = s1, y = s2)) +
  geom_point(aes(color = y1, size = y1), alpha = 0.75) +
  scale_color_distiller(palette = "RdYlGn", direction = -1,
                        label = function(x) sprintf("%.0f", x)) +
  guides(alpha = 'none', size = 'none') + 
  xlab("Easting") + ylab("Northing") +
  labs(color = TeX('$y(s)$')) + theme_bw() +
  theme(axis.ticks = element_line(linewidth = 0.25),
        panel.background = element_blank(),
        panel.grid = element_blank(), 
        legend.title = element_text(size = 10, hjust = 0.25), 
        legend.box.just = "center", aspect.ratio = 1)

pbinom2 <- ggplot(simdat2, aes(x = s1, y = s2)) +
  geom_point(aes(color = y2, size = y2), alpha = 0.75) +
  scale_color_distiller(palette = "PuOr", direction = 1,
                        label = function(x) sprintf("%.0f", x)) +
  guides(alpha = 'none', size = 'none') + 
  xlab("Easting") + ylab("Northing") +
  labs(color = TeX('$y(s)$')) + theme_bw() +
  theme(axis.ticks = element_line(linewidth = 0.25),
        panel.background = element_blank(),
        panel.grid = element_blank(), 
        legend.title = element_text(size = 10, hjust = 0.25), 
        legend.box.just = "center", aspect.ratio = 1)
```
```{r, fig.cap="Simulated point-referenced binomial count data - (a) observed count, (b) maximum possible count."}
# Plot point-referenced binomial counts
ggarrange(pbinom1, pbinom2, nrow = 1)
```

### Fitting binomial regression using stacking

We follow similar steps to implement our stacking algorithm for binomial regression. First we store the corresponding variables. The variable `y2` in the simulated data corresponds to the vector of maximum possible counts at each location. Then we build the list of candidate models based on some candidate values of the model parameters.
```{r}
y <- as.numeric(simdat2$y1)
y_binom <- as.numeric(simdat2$y2)
X <- as.matrix(simdat2[, grep("x", names(simdat2))])
S <- as.matrix(simdat2[, c("s1", "s2")])

# Number of posterior samples
n_postsamp <- 500

# supply grid of values: G_decay, G_smoothness, G_epsilon
mod_list <- create_model_list(G_decay = c(3, 4, 10), 
                              G_smoothness = c(0.5, 1, 1.5),
                              G_epsilon = c(0.25, 0.5),
                              G_nuxi = 0, G_nubeta = 2.1, G_nuz = 2.1)
```

We then run our stacking algorithm using the function `spGLM_stack()` with the option `family = "binomial"` and `n_binom = y_binom`.
```{r stack2, cache=TRUE, cache.path="cache/"}
m_out <- spGLM_stack(y = y, X = X, S = S, N.samp = n_postsamp,
                     family = "binomial", n_binom = y_binom,
                     spCov = "matern", mc.cores = 6,
                     mod_params_list = mod_list)
```

After the model is fit, we sample from the posterior distribution of the model parameters specific to each candidate model according to their corresponding stacking weights and then analyse the results.
```{r}
postrun_samps <- postrunsampler(m_out, N.samp = n_postsamp)
post_z <- postrun_samps$z
post_beta <- postrun_samps$beta

# Print credible intervals of fixed effects
print(ci_beta(t(post_beta)))
```

```{r, eval = FALSE, echo = FALSE, fig.cap='Interpolated surface of (a) true spatial effects and (b) posterior median of spatial effects obtained by stacking'}
simdat2$postmedian_z <- apply(post_z, 1, median)
leg_title <- TeX('$z(s)$')
pbinom_z1 <- pointref_plot(simdat2, "z", legend_title = leg_title, mark_points = TRUE)
pbinom_z2 <- pointref_plot(simdat2, "postmedian_z", legend_title = leg_title)
ggarrange(pbinom_z1, pbinom_z2, nrow = 1, labels = 'auto',
          common.legend = TRUE, legend="right")
```

# Spatially-temporally varying coefficient (STVC) model

we consider a spatial-temporal process as an uncountable set of random variables, say $\{z(\ell): \ell\in \calD\}$, over a domain of interest $\calD$. Suppose $\calL = \{\ell_1, \ldots, \ell_n\}$ denotes $n$ space-time coordinates. We consider a STVC model for spatial-temporal data as
\begin{equation}
y(\ell_i) \sim \mathrm{EF}(x(\ell_i)^\T \beta + \tilde{x}(\ell_i)^\T z(\ell_i)), \quad i = 1, \dots, n.\\
(\#eq:stvc)
\end{equation}
where $x(\ell_i)$ is a $p\times 1$ vector of predictors, $\beta$ is the corresponding $p \times 1$ vector of slopes (fixed effects), $\tilde{x}(\ell_i)$ is the $r\times 1$ vector ($r \leq p$) consisting of those predictors in $x(\ell_i)$ that are posited to have spatially varying regression coefficients, and $z_j = (z_j(\ell_1),\ldots,z_j(\ell_n))^{\T}$ is $n\times 1$ with each $z_j(\ell_i)$ being a spatially-temporally varying coefficient for the predictor $\tilde{x}_j(\ell_i)$. We assume $z_j(\ell) \overset{\text{ind.}}{\sim} \CMP(\mu_{z_j}(\ell), \sigma_{z_j}^2 R_j(\cdot, \cdot; \thetasp_j))$ for each $j$, are a collection of $r$ independent $\CM$ processes with their respective parameters and log partition functions. We model the elements of $R_j(\thetasp_j)$ using the spatial-temporal correlation function
\begin{equation}
R_j(\ell, \ell'; \thetasp_j) = \frac{1}{ \phi_{tj} |t-t'|^2+1 } \exp\left(  -\frac{\phi_{sj} \| s-s' \| }{\sqrt{1+\phi_{tj} |t-t'|^2} }   \right),\quad \phi_{tj},\phi_{sj}>0 \;,
(\#eq:corrfn)
\end{equation}
where $\ell=(s,t)$ and $\ell'=(s',t')$ are any two distinct space-time coordinates, $\|\cdot\|$ is the Euclidean distance over $\calS$, $\thetasp_j = (\phi_{tj}, \phi_{sj})$ are positive spatial and temporal decay parameters, respectively. Technical details can be found in ``our paper''.

## Simulation of a STVC dataset

We simulate a spatial-temporal Poisson count dataset of sample size 100 from \@ref(eq:stvc) with spatial-temporal processes with covariogram \@ref(eq:corrfn) in each regression coefficient. We include an intercept and a predictor sampled from a standard normal distribution and consider $\tilde{x}(\ell_i) = x(\ell_i)$ for all $i$. We choose different values for the spatial and temporal decay parameters for the each process. In particular, we take $(\phi_{t1}, \phi_{s1}) = (0.5, 2)$ and $(\phi_{t2}, \phi_{s2}) = (1, 4)$ for the spatial-temporal processes corresponding to the intercept and the predictor respectively. We also consider the marginal variances of the processes to be 0.25 ad 0.5 respectively. We choose such values to ensure we are sampling the true spatial-temporal random effects from processes characterized by different parameters.

```{r sim3, cache=TRUE, cache.path="cache/"}
set.seed(1729)
simdat <- sim_sptv_continuous(n = 100, beta = c(5, -0.5),
                              phi_s = c(2, 4), phi_t = c(0.5, 1),
                              sz = c(0.25, 0.5))
```

## Fitting STVC model using stacking

Next, we create a list of candidate models using the function `create_candidate_models()` by passing a list with each item containing candidate values for each model parameter that we condition on in order to produce tractable posterior distributions. For practical reasons, we consider a \emph{reduced} model that assumes a pair of common process parameter shared across all spatial-temporal processes in the regression coefficients.

```{r}
y <- as.numeric(simdat$y)
X <- as.matrix(simdat[, grep("x", names(simdat))])
S <- as.matrix(simdat[, c("s1", "s2")])
time <- as.numeric(simdat$time)

# Number of posterior samples
n_postsamp <- 500

# supply grid of candidate values of model parameters
mod_list <- list(G_phi_s = c(2, 3, 5), G_phi_t = c(0.25, 0.75, 1.5),
                 G_epsilon = c(0.25, 0.5), G_nu_xi = c(1), 
                 G_nu_beta = c(3), G_nu_z = c(3))

# create candidate model list
mod_list <- create_candidate_models(mod_list)
```

Then, we pass the list of candidate models and the data into the function `sptvGLM_stack` with other essential options as discussed earlier.

```{r stack3, cache=TRUE, cache.path="cache/"}
m_out <- sptvGLM_stack(y = y, X = X, X_tilde = X, S = S, time = time,
                       N.samp = n_postsamp, MC.samp = 200,
                       family = "poisson",
                       mc.cores = 6, solver = "MOSEK",
                       mod_params_list = mod_list)
```

Finally, we use the optimal weights to sample from the stacked posterior and present the posterior summary of the fixed regression coefficients.

```{r}
postrun_samps <- postrunsampler_sptv(m_out, N.samp = n_postsamp)
post_z_stack <- postrun_samps$z
post_xi_stack <- postrun_samps$xi
post_beta_stack <- postrun_samps$beta
print(ci_beta(t(post_beta_stack)))
```

## Fitting STVC model using MCMC

We also evaluate a fully Bayesian STVC model by assigning uniform priors on all the process parameters, using an adaptive Metropolis-within-Gibbs algorithm.

```{r mcmc2, cache=TRUE, cache.path="cache/"}
n_postsamp <- 10000

t_mcmc_start <- Sys.time()
mod_out <- sptvGLM_adaMetropGibbs(y = y, X = X, X_tilde = X, 
                                  S = S, time = time, 
                                  family = "poisson", 
                                  N.samp = n_postsamp, 
                                  starting = list(phi_s = c(3, 2.5), 
                                                  phi_t = c(1, 0.9),
                                                  beta = c(0, 0)), 
                                  prior = list(phi_s_a = c(0.5, 0.5),
                                               phi_s_b = c(10, 10),
                                               phi_t_a = c(0.5, 0.5),
                                               phi_t_b = c(10, 10),
                                               nu_xi = 1, nu_beta = 3,
                                               nu_z = 3, alpha_epsilon = 0.5),
                                  n.batch = 3, batch.length = 10)
t_mcmc_end <- Sys.time()
t_mcmc_elpased <- t_mcmc_end - t_mcmc_start
cat("Elapsed ", t_mcmc_elpased, units(t_mcmc_elpased), ".\n")
```

Finally, we collect the chain, remove 50\% burn-in samples, and thin it, storing every 10 samples to remove autocorrelation. We also present the posterior credible intervals for the fixed regression coefficients obtained by MCMC.

```{r}
burnin_pc <- 0.5           # percentage burn-in
n_thin <- 10               # consider every *-th sample

ids <- 1:n_postsamp
ids <- ids[-(1:(floor(burnin_pc * n_postsamp))+1)]
ids <- ids[c(rep(FALSE, n_thin - 1), TRUE)]

post_beta_mcmc <- mod_out$beta[, ids]
post_z_mcmc <- mod_out$z[, ids]
post_phi_s <- mod_out$phi_s[, ids]
post_phi_t <- mod_out$phi_t[, ids]

print(ci_beta(t(post_beta_mcmc)))
```

## Results 

### Comparison between stacking and MCMC

We compare the posterior distributions of the fixed effects and the random effects in the following plots. 

#### Posterior distributions of fixed effects

This figure shows the overlaid posterior densities of the fixed effects obtained from the stacked posterior (blue) and MCMC (red), revealing practically indistinguishable posterior distributions. 

```{r, echo=FALSE, warning=FALSE}
post_beta_combined1 <- as.data.frame(t(as.matrix(post_beta_mcmc)))
post_beta_combined2 <- as.data.frame(t(as.matrix(post_beta_stack)))
names(post_beta_combined1) <- c("beta0", "beta1")
names(post_beta_combined2) <- c("beta0", "beta1")
post_beta_combined1$Method <- "MCMC"
post_beta_combined2$Method <- "Stacking"
post_beta_combined <- rbind.data.frame(post_beta_combined1,
                                       post_beta_combined2,
                                       stringsAsFactors = TRUE)
row.names(post_beta_combined) <- NULL
post_beta_combined$Method <- factor(post_beta_combined$Method)

alpha_plot <- 0.25
plot_beta0 <- ggplot(data = post_beta_combined, aes(x = beta0)) +
  geom_density(aes(fill = Method, color = Method), 
               alpha = alpha_plot) +
  # scale_color_brewer(palette = "Set1") +
  xlim(2.0, 6.5) + xlab(latex2exp::TeX('$\\beta_1$')) + 
  ylab("Posterior density") + theme_bw() +
  # annotate("point", x = beta0[1], y = 0, pch = 24, fill = "#B4464B", size = 2) +
  # geom_vline(xintercept = beta0[1], linetype = "dotted") + 
  labs(title = "Intercept") +
  theme(panel.grid = element_blank(), 
        plot.title = element_text(hjust = 0.5),
        aspect.ratio = 1)
  # theme(panel.grid = element_blank(), legend.background = element_blank(),
  #       legend.title = element_text(face = "italic", hjust = 0.5),
  #       axis.title.y=element_blank(), aspect.ratio = 1)

plot_beta1 <- ggplot(data = post_beta_combined, aes(x = beta1)) +
  geom_density(aes(fill = Method, color = Method), 
               alpha = alpha_plot) +
  # scale_color_brewer(palette = "Set1") +
  xlim(-3.5, 2.5) + xlab(latex2exp::TeX('$\\beta_2$')) + 
  ylab("Posterior density") + theme_bw() +
  # annotate("point", x = beta0[2], y = 0, pch = 24, fill = "#B4464B", size = 2) + 
  # geom_vline(xintercept = beta0[2], linetype = "dotted") + 
  labs(title = "Slope") +
  theme(panel.grid = element_blank(), 
        plot.title = element_text(hjust = 0.5), 
        aspect.ratio = 1)
  # theme(panel.grid = element_blank(), legend.background = element_blank(),
  #       legend.title = element_text(face = "italic", hjust = 0.5),
  #       axis.title.y=element_blank(), aspect.ratio = 1)

plot_beta <- ggarrange(plot_beta0, plot_beta1, nrow = 1, 
                       common.legend = TRUE, legend="right")
```
```{r}
plot_beta
```

#### Posterior distributions of spatial-temporal random effects

The following figure displays high agreement between the posterior medians of the spatial-temporal random effects associated with the intercept and the slope, obtained by our proposed stacking algorithm and MCMC.

```{r, echo=FALSE, warning=FALSE}
z_stack_median <- apply(post_z_stack, 1, function(x) quantile(x, 0.5))
z_mcmc_median <- apply(post_z_mcmc, 1, function(x) quantile(x, 0.5))

z1_comb <- data.frame(z_stack = z_stack_median[1:100],
                      z_mcmc = z_mcmc_median[1:100])
z2_comb <- data.frame(z_stack = z_stack_median[1:100 + 100],
                      z_mcmc = z_mcmc_median[1:100 + 100])

plot_z1 <- ggplot(z1_comb, aes(x = z_stack, y = z_mcmc)) +
  geom_point(col = "grey20", size = 1, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = latex2exp::TeX('$z_1$')) +
  xlab("Stacking") + ylab("MCMC") +
  theme_bw() +
  theme(panel.grid = element_blank(), 
        plot.title = element_text(hjust = 0.5), 
        aspect.ratio = 1)

plot_z2 <- ggplot(z2_comb, aes(x = z_stack, y = z_mcmc)) +
  geom_point(col = "grey20", size = 1, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = latex2exp::TeX('$z_2$')) +
  xlab("Stacking") + ylab("MCMC") +
  theme_bw() +
  theme(panel.grid = element_blank(), 
        plot.title = element_text(hjust = 0.5), 
        aspect.ratio = 1)

plot_z <- ggarrange(plot_z1, plot_z2, nrow = 1, 
                    common.legend = FALSE, legend="right")
```
```{r}
plot_z
```

### Weak identifiability of process parameters

Lastly, we present histograms showing posterior distribution of the process parameters obtained by MCMC. The process parameters does not necessarily concentrate around their true values illustrating their weak identifiablity. In addition, we also observe similar patterns in the posterior distributions within the temporal ($\phi_{11}$ and $\phi_{12}$) and the spatial decay parameters ($\phi_{21}$ and $\phi_{22}$), which further motivates the assumptions of the \emph{reduced} model.

```{r, echo=FALSE, warning=FALSE}
post_spParams <- data.frame(vals = c(as.numeric(post_phi_t[1, ]), 
                                     as.numeric(post_phi_t[2, ]),
                                     as.numeric(post_phi_s[1, ]), 
                                     as.numeric(post_phi_s[2, ])),
                            params = rep(c("11", "12", 
                                           "21", "22"), 
                                         each = 500))
spParams_names <- list(
  '11' = TeX('$\\phi_{t1}$'), 
  '12' = TeX('$\\phi_{t2}$'),
  '21' = TeX('$\\phi_{s1}$'),
  '22' = TeX('$\\phi_{s2}$')
)
spParams_labeller <- function(variable,value){
  return(spParams_names[value])
}

plot_phi <- ggplot(post_spParams, aes(x = vals)) + 
  geom_histogram(aes(y = after_stat(density)), bins = 30,
                 color = "black", fill = "royalblue4", 
                 alpha = 0.5, linewidth = 0.25) + 
  geom_density(fill = "skyblue", alpha = 0.25) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
  xlab("") + ylab("Posterior density") +
  facet_wrap(~ params, labeller = spParams_labeller, scales = 'free') +
  theme_bw() + 
  theme(panel.grid = element_blank(),
        aspect.ratio = 1,
        strip.text = element_text(size = 12))
```
```{r, fig.height=5}
plot_phi
```


# References {-}

<div id="refs"></div>

### Session information {-}

```{r}
sessionInfo()
```
